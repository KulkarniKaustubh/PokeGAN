{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "import tensorflow.keras.layers as layers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'pokemon'\n",
    "imageSize = 28\n",
    "\n",
    "# getting training data\n",
    "X_train = []\n",
    "\n",
    "numImages = 0\n",
    "for image in os.listdir(DATA_PATH):\n",
    "    numImages += 1\n",
    "    readImage = cv2.imread(os.path.join(DATA_PATH, image))\n",
    "    readImage = cv2.resize(readImage, (imageSize, imageSize))\n",
    "    X_train.append(readImage)\n",
    "\n",
    "X_train = np.array(X_train).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(819, 28, 28, 3)\n",
      "7\n",
      "128\n",
      "51\n",
      "28\n",
      "28\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# 819 images of size (200, 200) with 3 channels\n",
    "print(X_train.shape)\n",
    "\n",
    "BUFFER = X_train.shape[0]\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "trainingData = tf.data.Dataset.from_tensor_slices(X_train).shuffle(BUFFER).batch(BATCH_SIZE)\n",
    "\n",
    "# just to check dimension\n",
    "lst = list(trainingData.as_numpy_iterator())\n",
    "print(len(lst))\n",
    "print(len(lst[0]))\n",
    "print(len(lst[-1]))\n",
    "print(len(lst[0][0]))\n",
    "print(len(lst[0][0][0]))\n",
    "print(len(lst[0][0][0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "- Discriminator model\n",
    "- Generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.backend.clear_session()\n",
    "\n",
    "def getDiscriminatorModel():\n",
    "    model = K.models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), padding = 'same', input_shape = (imageSize, imageSize, 3)),\n",
    "        layers.LeakyReLU(),\n",
    "        \n",
    "        layers.Conv2D(64, (3, 3), strides = (2, 2), padding = 'same'),\n",
    "        layers.LeakyReLU(),\n",
    "        \n",
    "        layers.Conv2D(128, (3, 3), strides = (2, 2), padding = 'same'),\n",
    "        layers.LeakyReLU(),\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1),\n",
    "    ], name = \"discriminator sequential model\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = getDiscriminatorModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator sequential model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 6273      \n",
      "=================================================================\n",
      "Total params: 99,521\n",
      "Trainable params: 99,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the summary above, we see that we get a 7x7x128 just before flattenning\n",
    "nodes = 7*7*128\n",
    "\n",
    "def getGeneratorModel():\n",
    "    model = K.models.Sequential([\n",
    "        layers.Dense(nodes, input_shape = (100,)),\n",
    "        # shouldn't explode\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Reshape((7, 7, 128)),\n",
    "        layers.LeakyReLU(),\n",
    "        \n",
    "        layers.Conv2DTranspose(128, (3, 3), padding = 'same'),\n",
    "        layers.LeakyReLU(),\n",
    "        \n",
    "        layers.Conv2DTranspose(64, (3, 3), strides = (2, 2), padding = 'same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(),\n",
    "        \n",
    "        layers.Conv2DTranspose(32, (3, 3), strides = (2, 2), padding = 'same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(),\n",
    "        \n",
    "        # at this point the image is upsampled twice so we have 7*2*2 shaped image\n",
    "        layers.Conv2DTranspose(1, (3, 3), padding = 'same')\n",
    "    ], name = 'generator sequential model')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = getGeneratorModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator sequential model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 6272)              25088     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 7, 7, 128)         147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 32)        18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         289       \n",
      "=================================================================\n",
      "Total params: 899,073\n",
      "Trainable params: 886,337\n",
      "Non-trainable params: 12,736\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd967c0c970>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# testing the generator with some noise\n",
    "noise = tf.random.normal([2, 100])\n",
    "genImgs = generator(noise, training = False)\n",
    "print(genImg.shape)\n",
    "plt.imshow(genImg[0, :, :, 0], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "genOpt = K.optimizers.Adam(lr = 1e-4)\n",
    "discOpt = K.optimizers.Adam(lr = 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGeneratorLoss(fakePreds):\n",
    "    return K.losses.BinaryCrossentropy(tf.ones_like(fakePreds), fakePreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDiscriminatorLoss(realPreds, fakePreds):\n",
    "    rLoss = K.losses.BinaryCrossentropy(tf.ones_like(realPreds), realPreds)\n",
    "    fLoss = K.losses.BinaryCrossentropy(tf.zeros_like(fakePreds), fakePreds)\n",
    "    totalLoss = rLoss + fLoss\n",
    "    return totalLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        print(\"Running epoch : \" + str(epoch + 1))\n",
    "        \n",
    "        for pokemon in dataset:\n",
    "            trainStep(pokemon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this decorator is used to \n",
    "@tf.function\n",
    "def trainStep(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, 100])\n",
    "    \n",
    "    with tf.GradientTape() as gen, tf.gradientTape() as disc:\n",
    "        genImages = generator(noise, training = True)\n",
    "        \n",
    "        realOP = discriminator(images, training = True)\n",
    "        fakeOP = discriminator(genImages, training = True)\n",
    "        \n",
    "        genLoss = getGeneratorLoss(fakeOP)\n",
    "        discLoss = getDiscriminatorLoss(realOP, fakeOP)\n",
    "        \n",
    "    genGrads = gen.gradient(genLoss, generator.trainable_variables)\n",
    "    discGrads = disc.gradient(discLoss, discriminator.trainable_variables)\n",
    "    \n",
    "    genOpt.apply_gradients(zip(genGrads, generator.trainable_variables))\n",
    "    discOpt.apply_gradients(zip(discGrads, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
